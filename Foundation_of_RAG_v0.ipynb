{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4LI-3UIRuUW"
      },
      "outputs": [],
      "source": [
        "!uv pip install -U --quiet loguru"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "from loguru import logger"
      ],
      "metadata": {
        "id": "vHDH7Imyl_Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Secret setup"
      ],
      "metadata": {
        "id": "qwIvPCtFowy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Gemini API (replace with your actual API key)\n",
        "genai.configure(api_key=)"
      ],
      "metadata": {
        "id": "15sBJxAll_9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build KB"
      ],
      "metadata": {
        "id": "9HNZ90r4o0tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise the model\n",
        "model = genai.GenerativeModel('gemini-1.5-pro')\n",
        "\n",
        "# Initialize sentence transformer for embedding\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Sample knowledge base\n",
        "knowledge_base = [\n",
        "    \"The capital of France is Paris.\",\n",
        "    \"The Eiffel Tower is located in Paris.\",\n",
        "    \"The Louvre Museum houses the Mona Lisa painting.\",\n",
        "    \"French cuisine is known for dishes like croissants and baguettes.\",\n",
        "    \"The French Revolution began in 1789.\",\n",
        "    \"Paris is divided into 20 arrondissements or districts.\",\n",
        "    \"The Seine River flows through the heart of Paris.\",\n",
        "    \"Notre-Dame Cathedral is a famous Parisian landmark.\",\n",
        "    \"Paris is often referred to as the 'City of Light'.\",\n",
        "    \"The Paris Metro is one of the busiest subway systems in Europe.\",\n",
        "    \"Soumendra is an AI Observability architetc in Pepsico\"\n",
        "]"
      ],
      "metadata": {
        "id": "z6t4N3-Xm82j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to retrieve relevant context\n",
        "def retrieve_context(query, knowledge_base, top_k=2):\n",
        "    query_embedding = embedder.encode([query])\n",
        "    context_embeddings = embedder.encode(knowledge_base)\n",
        "\n",
        "    similarities = cosine_similarity(query_embedding, context_embeddings)[0]\n",
        "    top_indices = np.argsort(similarities)[-top_k:]\n",
        "\n",
        "    return [knowledge_base[i] for i in reversed(top_indices)]\n",
        "\n",
        "# Function to generate response using Gemini\n",
        "def generate_response(query, context):\n",
        "    prompt = f\"Context: {' '.join(context)}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "# Main RAG function\n",
        "def rag_with_gemini(query):\n",
        "    context = retrieve_context(query, knowledge_base)\n",
        "    logger.info(f\"{context=}\")\n",
        "    logger.info(f\"{query=}\")\n",
        "    response = generate_response(query, context)\n",
        "    return response"
      ],
      "metadata": {
        "id": "SuUigoK2nHLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "query = input()\n",
        "answer = rag_with_gemini(query)\n",
        "print(f\"Question: {query}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "VBFUxLibnNhh",
        "outputId": "37376967-7e71-48a3-a94e-56e271a485e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "who is soumendra\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-06-08 06:20:43.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrag_with_gemini\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mcontext=['Soumendra is an AI Observability architetc in Pepsico', 'The Eiffel Tower is located in Paris.']\u001b[0m\n",
            "\u001b[32m2025-06-08 06:20:43.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrag_with_gemini\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mquery='who is soumendra'\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: who is soumendra\n",
            "Answer: Soumendra is an AI Observability architect at PepsiCo.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cdSdRlSLnUoq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
